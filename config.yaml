batch_size:
  desc: Batch size to use for train/val/test loading
  value: 32
lr:
  desc: Learning rate to use for Adam
  value: 0.0001
epochs:
  desc: Number of epochs
  value: 20
transformer_model:
  desc: Which Hugging Face transformer model to use
# value: nlptown/bert-base-multilingual-uncased-sentiment
  value: cardiffnlp/twitter-roberta-base-sentiment
transformer_out:
  desc: The number of output values of the transformer
# value: 5
  value: 3
freeze_transformer:
  desc: If true, freezes transformer weights, or fine-tune them otherwise
  value: True
train_size:
  desc: Portion of data to use for training
  value: 0.8
val_size:
  desc: Portion of data to use for validation
  value: 0.1
hidden_dim:
  desc: Hidden dimension to use for the movement predictor
  value: 32
device:
  desc: Which device to use for training
  value: ~
classify_threshold_down:
  desc: Threshold for when a course is classified as going DOWN
  value: -0.005
classify_threshold_up:
  desc: Threshold for when a course is classified as going UP
  value: +0.007 # +0.0055
min_tweets_day:
  desc: Minimum number of tweets about a stock on one day for a movement to be considered as a sample
  value: 5